import time
import feedparser
from datetime import datetime
from feedgen.feed import FeedGenerator

# 聚合列表
url_list = [
    "https://bangumi.moe/rss/latest",
    "https://mikanani.me/RSS/Classic",
    "https://acg.rip/.xml",
    "https://share.dmhy.org/topics/rss/rss.xml",
    "https://share.acgnx.se/rss.xml",
    "https://share.dmhy.org/topics/rss/rss.xml"
]

rss_feeds = {}

# 读取 url_list 中的 RSS feeds
for i in range(len(url_list)):
    rss_feeds[i] = feedparser.parse(url_list[i])

# 将所有 entries 添加如一个列表字典中
rss_feeds_entries = []

# 添加 entries 的数据
for i in range(len(rss_feeds)):
    for j in range(len(rss_feeds[i]['entries'])):
        if i != 5:
            new_map = {
                'title': rss_feeds[i]['entries'][j]['title'],
                'description': rss_feeds[i]['entries'][j]['summary'],
                'link': rss_feeds[i]['entries'][j]['link'],
                'id': rss_feeds[i]['entries'][j]['id'],
                'enclosure': rss_feeds[i]['entries'][j]['links'][1]['href'],
                'published': time.mktime(rss_feeds[i]['entries'][j]['published_parsed']),
            }
            rss_feeds_entries.append(new_map)
        else:
            new_map = {
                'title': rss_feeds[i]['entries'][j]['title'],
                'description': rss_feeds[i]['entries'][j]['summary'],
                'link': rss_feeds[i]['entries'][j]['id'],
                'id': rss_feeds[i]['entries'][j]['id'],
                'enclosure': rss_feeds[i]['entries'][j]['links'][0]['href'],
                'published': time.mktime(rss_feeds[i]['entries'][j]['published_parsed']),
            }
            rss_feeds_entries.append(new_map)

# 对 entries 进行时间戳排序
rss_feeds_entries_sorted = sorted(rss_feeds_entries, key=lambda x: x['published'], reverse=True)

# 新建一个 feed 生成器
new_feed = FeedGenerator()

# 生成 channel 中的元数据
new_feed.id("Bangumi")
new_feed.title('KookaburraNode233')
new_feed.link(href='https://KookaburraNode233.example.com/Bangumi.xml', rel='self', type="application/rss+xml")
new_feed.description('A RSS feed merged multiple bangumi RSS feeds generated by KookaburraNode233')
new_feed.logo('https://blog.keepnaive233.network/assets/img/favicons/favicon.ico')
new_feed.ttl('600')

# 将 entries 填入 feed 中
for i in range(len(rss_feeds_entries_sorted)):
    new_feed_entries = new_feed.add_entry(order='append')
    new_feed_entries.title(rss_feeds_entries_sorted[i]['title'])
    new_feed_entries.description(rss_feeds_entries_sorted[i]['description'])
    new_feed_entries.link(href=rss_feeds_entries_sorted[i]['link'], rel="alternate", type="text/html")
    new_feed_entries.enclosure(url=rss_feeds_entries_sorted[i]['enclosure'], type="application/x-bittorrent")
    new_feed_entries.id(rss_feeds_entries_sorted[i]['id'])
    new_feed_entries.published(str(datetime.utcfromtimestamp(rss_feeds_entries_sorted[i]['published']))+"+0000")

new_feed.rss_file('rss.xml')
